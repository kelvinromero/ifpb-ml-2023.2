{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelvinromero/ifpb-ml-2023.2/blob/main/Projeto_Thiago.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   https://archive.ics.uci.edu/dataset/109/wine\n",
        "\n",
        "\n",
        "*   https://archive.ics.uci.edu/dataset/19/car+evaluation\n",
        "\n",
        "*   https://archive.ics.uci.edu/dataset/545/rice"
      ],
      "metadata": {
        "id": "8a06gbvjyeae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "id": "ziZy_90Y3e2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7015ca7-9e42-44d2-8d95-fee483fca60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.3-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Wine"
      ],
      "metadata": {
        "id": "PzvjbNGL8qLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = fetch_ucirepo(id=109)\n",
        "# display(df)\n",
        "\n",
        "x = df.data.features\n",
        "y = df.data.targets\n",
        "\n",
        "#Normalizacao das Features\n",
        "dfx = x.values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(dfx)\n",
        "x = pd.DataFrame(x_scaled)"
      ],
      "metadata": {
        "id": "WQlun8zZA43w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "#Transformar em Array\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "y = y.ravel()\n",
        "\n",
        "#Clusters\n",
        "folds = 10\n",
        "\n",
        "kf = StratifiedKFold(n_splits = folds)\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for train_index, test_index in kf.split(x,y):\n",
        "  X_train.append(x[train_index])\n",
        "  X_test.append(x[test_index])\n",
        "\n",
        "  y_train.append(y[train_index])\n",
        "  y_test.append(y[test_index])\n",
        "\n",
        "y_test"
      ],
      "metadata": {
        "id": "5lqDiAhMCEg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "results1 = []\n",
        "results2 = []\n",
        "\n",
        "erros1 = []\n",
        "erros2 = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results1.append(acc)\n",
        "  erros1.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = DecisionTreeClassifier(criterion=\"gini\")\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results2.append(acc)\n",
        "  erros2.append(err)\n",
        "\n",
        "show1 = round(np.mean(results1) * 100)\n",
        "show2 = round(np.mean(results2) * 100)\n",
        "\n",
        "erro1= np.mean(erros1)\n",
        "erro2= np.mean(erros2)\n",
        "\n",
        "print(f'Taxa de Acerto com Entropy: {show1}%')\n",
        "print(f'Taxa de Erros com Entropy: {erro1}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com Gini: {show2}%')\n",
        "print(f'Taxa de Erros com Gini: {erro2}')"
      ],
      "metadata": {
        "id": "JxSjLwv986Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "results3 = []\n",
        "results4 = []\n",
        "\n",
        "erros3 = []\n",
        "erros4 = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean', algorithm = 'brute')\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results3.append(acc)\n",
        "  erros3.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = KNeighborsClassifier(n_neighbors = 10, metric = 'euclidean', algorithm = 'brute')\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results4.append(acc)\n",
        "  erros4.append(err)\n",
        "\n",
        "show3 = round(np.mean(results3) * 100)\n",
        "show4 = round(np.mean(results4) * 100)\n",
        "\n",
        "erro3 = np.mean(erros3)\n",
        "erro4 = np.mean(erros4)\n",
        "\n",
        "print(f'Taxa de Acerto com 5-NN {show3}%')\n",
        "print(f'Taxa de Erro com 5-NN {erro3}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com 10-NN {show4}%')\n",
        "print(f'Taxa de Erro com 10-NN {erro4}')"
      ],
      "metadata": {
        "id": "y_QOGfgGCioa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "results5 = []\n",
        "results6 = []\n",
        "results7 = []\n",
        "results8 = []\n",
        "\n",
        "erros5 = []\n",
        "erros6 = []\n",
        "erros7 = []\n",
        "erros8 = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = MLPClassifier(hidden_layer_sizes=(4,5), activation='relu', max_iter=2500)\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results5.append(acc)\n",
        "  erros5.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = MLPClassifier(hidden_layer_sizes=(4,5), activation='tanh', max_iter=2000)\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results6.append(acc)\n",
        "  erros6.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = MLPClassifier(hidden_layer_sizes=(3,5,2), activation='relu', max_iter=2800)\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results7.append(acc)\n",
        "  erros7.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = MLPClassifier(hidden_layer_sizes=(3,5,2), activation='tanh', max_iter=3000)\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results8.append(acc)\n",
        "  erros8.append(err)\n",
        "\n",
        "\n",
        "show5 = round(np.mean(results5) * 100)\n",
        "show6 = round(np.mean(results6) * 100)\n",
        "show7 = round(np.mean(results7) * 100)\n",
        "show8 = round(np.mean(results8) * 100)\n",
        "\n",
        "erro5 = np.mean(erros5)\n",
        "erro6 = np.mean(erros6)\n",
        "erro7 = np.mean(erros7)\n",
        "erro8 = np.mean(erros8)\n",
        "\n",
        "print(f'Taxa de Acerto com MLP 4x5 relu: {show5}%')\n",
        "print(f'Taxa de Erro com MLP 4x5 relu: {erro5}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com MLP 4x5 tanh: {show6}%')\n",
        "print(f'Taxa de Erro com MLP 4x5 tanh: {erro6}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com MLP 3x5x2 relu: {show6}%')\n",
        "print(f'Taxa de Erro com MLP 3x5x2 relu: {erro6}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com MLP 3x5x2 tanh: {show8}%')\n",
        "print(f'Taxa de Erro com MLP 3x5x2 tanh: {erro8}')"
      ],
      "metadata": {
        "id": "-nQ_kbq4DEJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Mapping\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "\n",
        "# Verifica a quantidade de 'clusters'\n",
        "clusters = df.data.targets.value_counts().shape[0]\n",
        "\n",
        "# Aplit Dataset\n",
        "results9 = []\n",
        "erros9 = []\n",
        "resulteste = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = KMeans(n_clusters = clusters)\n",
        "  treino = model.fit(X_train[i])\n",
        "\n",
        "  # Pegar os labels dos padrões de Treinamento\n",
        "  labels = treino.labels_\n",
        "\n",
        "  map_labels = []\n",
        "\n",
        "  for j in range(clusters):\n",
        "    map_labels.append([])\n",
        "\n",
        "  new_y_train = y_train[i]\n",
        "\n",
        "  for j in range(len(y_train[i])):\n",
        "    for c in range(clusters):\n",
        "        if labels[j] == c:\n",
        "            map_labels[c].append(new_y_train[j])\n",
        "\n",
        "  # Criar dicionário com os labells a serem mapeados\n",
        "  mapping = {}\n",
        "\n",
        "  for j in range(clusters):\n",
        "    final = Counter(map_labels[j]) # contar a classe que mais aparece\n",
        "    value = final.most_common(1)[0][0] # retorna a classe com maior frequência\n",
        "    mapping[j] = value\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "  result = [mapping[i] for i in result]\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results9.append(acc)\n",
        "  erros9.append(err)\n",
        "  resulteste.append(result)\n",
        "\n",
        "\n",
        "show9 = round(np.mean(results9) * 100)\n",
        "erro9 = np.mean(erros9)\n",
        "\n",
        "print(f'Taxa de Acerto 2-Means: {show9}%')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Erro 2-Means: {erro9}')\n"
      ],
      "metadata": {
        "id": "PRSoPxVlEFUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico MLPs mostrando a taxa de erros\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# DataFrame01(dfMLP1) - MLP 4x5 relu\n",
        "epocas = [\"Epc-01\", \"Epc-02\", \"Epc-03\", \"Epc-04\", \"Epc-05\", \"Epc-06\", \"Epc-07\", \"Epc-08\", \"Epc-09\", \"Epc-10\"]\n",
        "\n",
        "dfMLP1 = pd.DataFrame({\n",
        "    \"Épocas\": epocas,\n",
        "    \"Acurácia\": results5,\n",
        "    \"Erro\": erros5\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem crescente\n",
        "dfMLP1 = dfMLP1.sort_values(\"Acurácia\", ascending=False)\n",
        "\n",
        "# Gráfico 01 MLP 4x5 relu\n",
        "plt.figure(figsize=(7, 3))\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.bar(dfMLP1[\"Épocas\"], dfMLP1[\"Erro\"], color=\"lightblue\")\n",
        "plt.title(\"Gráfico de Erros MLP 4x5 relu\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Erro\")\n",
        "for i in range(len(dfMLP1)):\n",
        "    plt.annotate(f\"{dfMLP1['Erro'].iloc[i]:.2f}\", (dfMLP1[\"Épocas\"].iloc[i], dfMLP1[\"Erro\"].iloc[i]), ha=\"center\", fontsize=8, weight=\"bold\")\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# DataFrame02(dfMLP2) - MLP 4x5 tanh\n",
        "dfMLP2 = pd.DataFrame({\n",
        "    \"Épocas\": epocas,\n",
        "    \"Acurácia\": results6,\n",
        "    \"Erro\": erros6\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem crescente\n",
        "dfMLP2 = dfMLP2.sort_values(\"Acurácia\", ascending=False)\n",
        "\n",
        "# Gráfico 02 MLP 4x5 tanh\n",
        "plt.figure(figsize=(7, 3))\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.bar(dfMLP2[\"Épocas\"], dfMLP2[\"Erro\"], color=\"lightgreen\")\n",
        "plt.title(\"Gráfico de Erros MLP 4x5 tanh\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Erro\")\n",
        "for i in range(len(dfMLP2)):\n",
        "    plt.annotate(f\"{dfMLP2['Erro'].iloc[i]:.2f}\", (dfMLP2[\"Épocas\"].iloc[i], dfMLP2[\"Erro\"].iloc[i]), ha=\"center\", fontsize=8, weight=\"bold\")\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# DataFrame03(dfMLP3) - MLP 3x5x2 relu\n",
        "dfMLP3 = pd.DataFrame({\n",
        "    \"Épocas\": epocas,\n",
        "    \"Acurácia\": results7,\n",
        "    \"Erro\": erros7\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem crescente\n",
        "dfMLP3 = dfMLP3.sort_values(\"Acurácia\", ascending=False)\n",
        "\n",
        "# Gráfico 03 MLP 3x5x2 relu\n",
        "plt.figure(figsize=(7, 3))\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.bar(dfMLP3[\"Épocas\"], dfMLP3[\"Erro\"], color=\"lightcyan\")\n",
        "plt.title(\"Gráfico de Erros MLP 3x5x2 relu\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Erro\")\n",
        "for i in range(len(dfMLP3)):\n",
        "    plt.annotate(f\"{dfMLP3['Erro'].iloc[i]:.2f}\", (dfMLP3[\"Épocas\"].iloc[i], dfMLP3[\"Erro\"].iloc[i]), ha=\"center\", fontsize=8, weight=\"bold\")\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# DataFrame04(dfMLP4) - MLP 3x5x2 tanh\n",
        "dfMLP4 = pd.DataFrame({\n",
        "    \"Épocas\": epocas,\n",
        "    \"Acurácia\": results8,\n",
        "    \"Erro\": erros8\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem crescente\n",
        "dfMLP4 = dfMLP4.sort_values(\"Acurácia\", ascending=False)\n",
        "\n",
        "# Gráfico 04 MLP 3x5x2 tanh\n",
        "plt.figure(figsize=(7, 3))\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.bar(dfMLP4[\"Épocas\"], dfMLP4[\"Erro\"], color=\"lightcoral\")\n",
        "plt.title(\"Gráfico de Erros MLP 3x5x2 tanh\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Erro\")\n",
        "for i in range(len(dfMLP4)):\n",
        "    plt.annotate(f\"{dfMLP4['Erro'].iloc[i]:.2f}\", (dfMLP4[\"Épocas\"].iloc[i], dfMLP4[\"Erro\"].iloc[i]), ha=\"center\", fontsize=8, weight=\"bold\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "im7dTcp2EmrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algoritmos = [\"Árvore Entropia\", \"Árvore Gini\", \"5-NN\", \"10-NN\", \"MLP 4x5 relu\", \"MLP 4x5 tanh\", \"MLP 3x5x2 relu\", \"MLP 3x5x2 tanh\", \"2-Means\"]\n",
        "acuracias = [\"{:.2f}%\".format(show1), \"{:.2f}%\".format(show2), \"{:.2f}%\".format(show3), \"{:.2f}%\".format(show4),\n",
        "             \"{:.2f}%\".format(show5), \"{:.2f}%\".format(show6), \"{:.2f}%\".format(show7), \"{:.2f}%\".format(show8), \"{:.2f}%\".format(show9)]\n",
        "erros = [\"{:.2f}\".format(erro1), \"{:.2f}\".format(erro2), \"{:.2f}\".format(erro3), \"{:.2f}\".format(erro4), \"{:.2f}\".format(erro5),\n",
        "         \"{:.2f}\".format(erro6), \"{:.2f}\".format(erro7), \"{:.2f}\".format(erro8), \"{:.2f}\".format(erro9)]\n",
        "\n",
        "# CDataFrame com as Taxas Acurácia/Erros\n",
        "dfTaxas = pd.DataFrame({\n",
        "    \"Algorítmos\": algoritmos,\n",
        "    \"% Acerto\": acuracias,\n",
        "    \"Erros\": erros\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem decrescente\n",
        "dfMelhor = dfTaxas.sort_values(\"% Acerto\", ascending=False)\n",
        "\n",
        "print('Ordenado pela ordem de execução dos Algorítmos:')\n",
        "display(dfTaxas)\n",
        "\n",
        "print()\n",
        "print('Ordenado pela melhor % de Acerto:')\n",
        "display(dfMelhor)"
      ],
      "metadata": {
        "id": "gRAsFvRZFBD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Car Evaluation\n"
      ],
      "metadata": {
        "id": "wJcz-E5oFmrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = fetch_ucirepo(id=19)\n",
        "# display(df)\n",
        "url =\"https://archive.ics.uci.edu/static/public/19/data.csv\"\n",
        "\n",
        "df = pd.read_csv(url, header=0)\n",
        "df = df.dropna()\n",
        "\n",
        "y = df['class']\n",
        "x = df.drop('class', axis=1)\n",
        "\n",
        "#OneHotEncoding na Feature\n",
        "column_transformer = make_column_transformer((OneHotEncoder(), ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']), remainder='passthrough')\n",
        "\n",
        "df = column_transformer.fit_transform(df)\n",
        "\n",
        "df = pd.DataFrame(data=df)\n",
        "\n",
        "#Separar Target de Feature\n",
        "x = df.drop(21, axis=1)\n",
        "y = df[21]\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "#Normalizacao\n",
        "x = x.values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "X = pd.DataFrame(x_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FHQ98JSjFv0_",
        "outputId": "74097d1b-5731-4e5a-d481-ac4f8c6fd386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 2, 1, 3])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# Transforma para Array NumPy\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "#y = y.ravel()\n",
        "\n",
        "# Total de clusters\n",
        "folds = 10\n",
        "\n",
        "kf = StratifiedKFold(n_splits = folds)\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for train_index, test_index in kf.split(X,y):\n",
        "  X_train.append(X[train_index])\n",
        "  X_test.append(X[test_index])\n",
        "\n",
        "  y_train.append(y[train_index])\n",
        "  y_test.append(y[test_index])\n"
      ],
      "metadata": {
        "id": "fKTahxAWVvA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "results1 = []\n",
        "results2 = []\n",
        "\n",
        "erros1 = []\n",
        "erros2 = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results1.append(acc)\n",
        "  erros1.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = DecisionTreeClassifier(criterion=\"gini\")\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results2.append(acc)\n",
        "  erros2.append(err)\n",
        "\n",
        "show1 = round(np.mean(results1) * 100)\n",
        "show2 = round(np.mean(results2) * 100)\n",
        "\n",
        "erro1= np.mean(erros1)\n",
        "erro2= np.mean(erros2)\n",
        "\n",
        "print(f'Taxa de Acerto com Entropy: {show1}%')\n",
        "print(f'Taxa de Erros com Entropy: {erro1}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com Gini: {show2}%')\n",
        "print(f'Taxa de Erros com Gini: {erro2}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DWxGJkRV6b8",
        "outputId": "7a2559f6-3ea7-4dd7-8d09-4d44bf8ff73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia Árvore com Entropy: 84.00%\n",
            "[0.7225433526011561, 0.7630057803468208, 0.9248554913294798, 0.7109826589595376, 0.8323699421965318, 0.9248554913294798, 0.9190751445086706, 0.8728323699421965, 0.9186046511627907, 0.8488372093023255]\n",
            "Erro Árvore com Entropy: 0.55\n",
            "[1.2023121387283238, 0.861271676300578, 0.30057803468208094, 1.0520231213872833, 0.7803468208092486, 0.3236994219653179, 0.2543352601156069, 0.30057803468208094, 0.27325581395348836, 0.18604651162790697]\n",
            "\n",
            "Acurácia Árvore com Gini: 85.00%\n",
            "[0.7572254335260116, 0.791907514450867, 0.9132947976878613, 0.6763005780346821, 0.8497109826589595, 0.9248554913294798, 0.8959537572254336, 0.861271676300578, 0.9127906976744186, 0.9302325581395349]\n",
            "Erro Árvore com Gini: 0.55\n",
            "[1.115606936416185, 0.815028901734104, 0.31213872832369943, 1.2080924855491328, 0.6358381502890174, 0.3236994219653179, 0.41040462427745666, 0.31213872832369943, 0.29651162790697677, 0.06976744186046512]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#from sklearn.metrics import mean_squared_error, r2_score\n",
        "#from sklearn import metrics\n",
        "\n",
        "results3 = []\n",
        "results4 = []\n",
        "\n",
        "erros3 = []\n",
        "erros4 = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean', algorithm = 'brute')\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results3.append(acc)\n",
        "  erros3.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = KNeighborsClassifier(n_neighbors = 10, metric = 'euclidean', algorithm = 'brute')\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results4.append(acc)\n",
        "  erros4.append(err)\n",
        "\n",
        "show3 = round(np.mean(results3) * 100)\n",
        "show4 = round(np.mean(results4) * 100)\n",
        "\n",
        "erro3 = np.mean(erros3)\n",
        "erro4 = np.mean(erros4)\n",
        "\n",
        "print(f'Taxa de Acerto com 5-NN {show3}%')\n",
        "print(f'Taxa de Erro com 5-NN {erro3}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com 10-NN {show4}%')\n",
        "print(f'Taxa de Erro com 10-NN {erro4}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5ZuuYaYW2ia",
        "outputId": "4d7ddf83-61da-4b51-a37f-253d0200221d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia 5-NN: 72.00%\n",
            "[0.5086705202312138, 0.5028901734104047, 0.6647398843930635, 0.6647398843930635, 0.8034682080924855, 0.6936416184971098, 0.861271676300578, 0.8323699421965318, 0.8197674418604651, 0.8081395348837209]\n",
            "Erro 5-NN: 1.15\n",
            "[2.0173410404624277, 2.040462427745665, 1.393063583815029, 1.393063583815029, 0.8208092485549133, 1.30635838150289, 0.5895953757225434, 0.6358381502890174, 0.7674418604651163, 0.5581395348837209]\n",
            "\n",
            "10-NN: 79.00%\n",
            "[0.7167630057803468, 0.7167630057803468, 0.7109826589595376, 0.884393063583815, 0.7687861271676301, 0.7630057803468208, 0.884393063583815, 0.8265895953757225, 0.8023255813953488, 0.813953488372093]\n",
            "Erro 10-NN: 0.86\n",
            "[1.1849710982658959, 1.1849710982658959, 1.2080924855491328, 0.5144508670520231, 0.976878612716763, 1.0289017341040463, 0.4277456647398844, 0.653179190751445, 0.8197674418604651, 0.5988372093023255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "#from sklearn.metrics import mean_squared_error, r2_score\n",
        "#from sklearn import metrics\n",
        "\n",
        "results5 = []\n",
        "results6 = []\n",
        "results7 = []\n",
        "results8 = []\n",
        "\n",
        "erros5 = []\n",
        "erros6 = []\n",
        "erros7 = []\n",
        "erros8 = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = MLPClassifier(hidden_layer_sizes=(4,5), activation='relu', max_iter=800)\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results5.append(acc)\n",
        "  erros5.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = MLPClassifier(hidden_layer_sizes=(4,5), activation='tanh', max_iter=1000)\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results6.append(acc)\n",
        "  erros6.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = MLPClassifier(hidden_layer_sizes=(4,5,3), activation='relu', max_iter=800)\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results7.append(acc)\n",
        "  erros7.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = MLPClassifier(hidden_layer_sizes=(4,5,3), activation='tanh', max_iter=1000)\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results8.append(acc)\n",
        "  erros8.append(err)\n",
        "\n",
        "\n",
        "show5 = round(np.mean(results5) * 100)\n",
        "show6 = round(np.mean(results6) * 100)\n",
        "show7 = round(np.mean(results7) * 100)\n",
        "show8 = round(np.mean(results8) * 100)\n",
        "\n",
        "erro5 = np.mean(erros5)\n",
        "erro6 = np.mean(erros6)\n",
        "erro7 = np.mean(erros7)\n",
        "erro8 = np.mean(erros8)\n",
        "\n",
        "print(f'Taxa de Acerto com MLP 4x5 relu: {show5}%')\n",
        "print(f'Taxa de Erro com MLP 4x5 relu: {erro5}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com MLP 4x5 tanh: {show6}%')\n",
        "print(f'Taxa de Erro com MLP 4x5 tanh: {erro6}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com MLP 3x5x2 relu: {show7}%')\n",
        "print(f'Taxa de Erro com MLP 3x5x2 relu: {erro7}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com MLP 3x5x2 tanh: {show8}%')\n",
        "print(f'Taxa de Erro com MLP 3x5x2 tanh: {erro8}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKymjb1VXVL8",
        "outputId": "b7d40cac-6a24-479f-c49c-5322575ea7ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Mapping\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "\n",
        "# Verifica a quantidade de 'clusters'\n",
        "clusters = df.data.targets.value_counts().shape[0]\n",
        "\n",
        "# Aplit Dataset\n",
        "results9 = []\n",
        "erros9 = []\n",
        "resulteste = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = KMeans(n_clusters = clusters)\n",
        "  treino = model.fit(X_train[i])\n",
        "\n",
        "  # Pegar os labels dos padrões de Treinamento\n",
        "  labels = treino.labels_\n",
        "\n",
        "  map_labels = []\n",
        "\n",
        "  for j in range(clusters):\n",
        "    map_labels.append([])\n",
        "\n",
        "  new_y_train = y_train[i]\n",
        "\n",
        "  for j in range(len(y_train[i])):\n",
        "    for c in range(clusters):\n",
        "        if labels[j] == c:\n",
        "            map_labels[c].append(new_y_train[j])\n",
        "\n",
        "  # Criar dicionário com os labells a serem mapeados\n",
        "  mapping = {}\n",
        "\n",
        "  for j in range(clusters):\n",
        "    final = Counter(map_labels[j]) # contar a classe que mais aparece\n",
        "    value = final.most_common(1)[0][0] # retorna a classe com maior frequência\n",
        "    mapping[j] = value\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "  result = [mapping[i] for i in result]\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results9.append(acc)\n",
        "  erros9.append(err)\n",
        "  resulteste.append(result)\n",
        "\n",
        "\n",
        "show9 = round(np.mean(results9) * 100)\n",
        "erro9 = np.mean(erros9)\n",
        "\n",
        "print(f'Taxa de Acerto 2-Means: {show9}%')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Erro 2-Means: {erro9}')"
      ],
      "metadata": {
        "id": "zJMYRFjEdTXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico MLPs mostrando a taxa de erros\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# DataFrame01(dfMLP1) - MLP 4x5 relu\n",
        "epocas = [\"Epc-01\", \"Epc-02\", \"Epc-03\", \"Epc-04\", \"Epc-05\", \"Epc-06\", \"Epc-07\", \"Epc-08\", \"Epc-09\", \"Epc-10\"]\n",
        "\n",
        "dfMLP1 = pd.DataFrame({\n",
        "    \"Épocas\": epocas,\n",
        "    \"Acurácia\": results5,\n",
        "    \"Erro\": erros5\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem crescente\n",
        "dfMLP1 = dfMLP1.sort_values(\"Acurácia\", ascending=False)\n",
        "\n",
        "# Gráfico 01 MLP 4x5 relu\n",
        "plt.figure(figsize=(7, 3))\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.bar(dfMLP1[\"Épocas\"], dfMLP1[\"Erro\"], color=\"lightblue\")\n",
        "plt.title(\"Gráfico de Erros MLP 4x5 relu\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Erro\")\n",
        "for i in range(len(dfMLP1)):\n",
        "    plt.annotate(f\"{dfMLP1['Erro'].iloc[i]:.2f}\", (dfMLP1[\"Épocas\"].iloc[i], dfMLP1[\"Erro\"].iloc[i]), ha=\"center\", fontsize=8, weight=\"bold\")\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# DataFrame02(dfMLP2) - MLP 4x5 tanh\n",
        "dfMLP2 = pd.DataFrame({\n",
        "    \"Épocas\": epocas,\n",
        "    \"Acurácia\": results6,\n",
        "    \"Erro\": erros6\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem crescente\n",
        "dfMLP2 = dfMLP2.sort_values(\"Acurácia\", ascending=False)\n",
        "\n",
        "# Gráfico 02 MLP 4x5 tanh\n",
        "plt.figure(figsize=(7, 3))\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.bar(dfMLP2[\"Épocas\"], dfMLP2[\"Erro\"], color=\"lightgreen\")\n",
        "plt.title(\"Gráfico de Erros MLP 4x5 tanh\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Erro\")\n",
        "for i in range(len(dfMLP2)):\n",
        "    plt.annotate(f\"{dfMLP2['Erro'].iloc[i]:.2f}\", (dfMLP2[\"Épocas\"].iloc[i], dfMLP2[\"Erro\"].iloc[i]), ha=\"center\", fontsize=8, weight=\"bold\")\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# DataFrame03(dfMLP3) - MLP 3x5x2 relu\n",
        "dfMLP3 = pd.DataFrame({\n",
        "    \"Épocas\": epocas,\n",
        "    \"Acurácia\": results7,\n",
        "    \"Erro\": erros7\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem crescente\n",
        "dfMLP3 = dfMLP3.sort_values(\"Acurácia\", ascending=False)\n",
        "\n",
        "# Gráfico 03 MLP 3x5x2 relu\n",
        "plt.figure(figsize=(7, 3))\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.bar(dfMLP3[\"Épocas\"], dfMLP3[\"Erro\"], color=\"lightcyan\")\n",
        "plt.title(\"Gráfico de Erros MLP 3x5x2 relu\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Erro\")\n",
        "for i in range(len(dfMLP3)):\n",
        "    plt.annotate(f\"{dfMLP3['Erro'].iloc[i]:.2f}\", (dfMLP3[\"Épocas\"].iloc[i], dfMLP3[\"Erro\"].iloc[i]), ha=\"center\", fontsize=8, weight=\"bold\")\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# DataFrame04(dfMLP4) - MLP 3x5x2 tanh\n",
        "dfMLP4 = pd.DataFrame({\n",
        "    \"Épocas\": epocas,\n",
        "    \"Acurácia\": results8,\n",
        "    \"Erro\": erros8\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem crescente\n",
        "dfMLP4 = dfMLP4.sort_values(\"Acurácia\", ascending=False)\n",
        "\n",
        "# Gráfico 04 MLP 3x5x2 tanh\n",
        "plt.figure(figsize=(7, 3))\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.bar(dfMLP4[\"Épocas\"], dfMLP4[\"Erro\"], color=\"lightcoral\")\n",
        "plt.title(\"Gráfico de Erros MLP 3x5x2 tanh\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Erro\")\n",
        "for i in range(len(dfMLP4)):\n",
        "    plt.annotate(f\"{dfMLP4['Erro'].iloc[i]:.2f}\", (dfMLP4[\"Épocas\"].iloc[i], dfMLP4[\"Erro\"].iloc[i]), ha=\"center\", fontsize=8, weight=\"bold\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CWPzQoj3czxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algoritmos = [\"Árvore Entropia\", \"Árvore Gini\", \"5-NN\", \"10-NN\", \"MLP 4x5 relu\", \"MLP 4x5 tanh\", \"MLP 3x5x2 relu\", \"MLP 3x5x2 tanh\", \"2-Means\"]\n",
        "acertos = [\"{:.2f}%\".format(show1), \"{:.2f}%\".format(show2), \"{:.2f}%\".format(show3), \"{:.2f}%\".format(show4),\n",
        "             \"{:.2f}%\".format(show5), \"{:.2f}%\".format(show6), \"{:.2f}%\".format(show7), \"{:.2f}%\".format(show8), \"{:.2f}%\".format(show9)]\n",
        "erros = [\"{:.2f}\".format(erro1), \"{:.2f}\".format(erro2), \"{:.2f}\".format(erro3), \"{:.2f}\".format(erro4), \"{:.2f}\".format(erro5),\n",
        "         \"{:.2f}\".format(erro6), \"{:.2f}\".format(erro7), \"{:.2f}\".format(erro8), \"{:.2f}\".format(erro9)]\n",
        "\n",
        "# CDataFrame com as Taxas Acurácia/Erros\n",
        "dfTaxas = pd.DataFrame({\n",
        "    \"Algorítmos\": algoritmos,\n",
        "    \"% Acerto\": acertos,\n",
        "    \"Erros\": erros\n",
        "})\n",
        "\n",
        "# Ordenar o dataframe pela acurácia em ordem decrescente\n",
        "dfMelhor = dfTaxas.sort_values(\"% Acerto\", ascending=False)\n",
        "\n",
        "print('Ordenado pela ordem de execução dos Algorítmos:')\n",
        "display(dfTaxas)\n",
        "\n",
        "print()\n",
        "print('Ordenado pela melhor % de Acerto:')\n",
        "display(dfMelhor)"
      ],
      "metadata": {
        "id": "qn-3zu4Rc4G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Rice"
      ],
      "metadata": {
        "id": "NcYop1PDZ64i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning up data\n",
        "# from ucimlrepo import fetch_ucirepo\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "\n",
        "# df = fetch_ucirepo(id=545)\n",
        "url = \"https://archive.ics.uci.edu/static/public/545/data.csv\"\n",
        "df = pd.read_csv(url, header=0)\n",
        "\n",
        "y = df['Class']\n",
        "x = df.drop('Class', axis=1)\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "label_enconder = preprocessing.LabelEncoder()\n",
        "\n",
        "x = pd.DataFrame(min_max_scaler.fit_transform(x.values))\n",
        "y = label_enconder.fit_transform(y)\n"
      ],
      "metadata": {
        "id": "SAvnh8zuZ-zR"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# Transforma para Array NumPy\n",
        "X = np.array(x)\n",
        "y = np.array(y)\n",
        "#y = y.ravel()\n",
        "\n",
        "# Total de clusters\n",
        "folds = 10\n",
        "\n",
        "kf = StratifiedKFold(n_splits = folds)\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for train_index, test_index in kf.split(X,y):\n",
        "  X_train.append(X[train_index])\n",
        "  X_test.append(X[test_index])\n",
        "\n",
        "  y_train.append(y[train_index])\n",
        "  y_test.append(y[test_index])\n"
      ],
      "metadata": {
        "id": "DC8RdvQRbQKS"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Decision Tree\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "results1 = []\n",
        "results2 = []\n",
        "\n",
        "erros1 = []\n",
        "erros2 = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results1.append(acc)\n",
        "  erros1.append(err)\n",
        "\n",
        "for i in range(folds):\n",
        "  model = DecisionTreeClassifier(criterion=\"gini\")\n",
        "  treino = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = treino.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "  err = mean_squared_error(y_test[i], result)\n",
        "\n",
        "  results2.append(acc)\n",
        "  erros2.append(err)\n",
        "\n",
        "show1 = round(np.mean(results1) * 100)\n",
        "show2 = round(np.mean(results2) * 100)\n",
        "\n",
        "erro1= np.mean(erros1)\n",
        "erro2= np.mean(erros2)\n",
        "\n",
        "print(f'Taxa de Acerto com Entropy: {show1}%')\n",
        "print(f'Taxa de Erros com Entropy: {erro1}')\n",
        "\n",
        "print()\n",
        "print(f'Taxa de Acerto com Gini: {show2}%')\n",
        "print(f'Taxa de Erros com Gini: {erro2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6flpM7IshHJD",
        "outputId": "9b5fafda-913c-467c-8141-a7ad3ea33637"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taxa de Acerto com Entropy: 88%\n",
            "Taxa de Erros com Entropy: 0.1152230971128609\n",
            "\n",
            "Taxa de Acerto com Gini: 88%\n",
            "Taxa de Erros com Gini: 0.1152230971128609\n"
          ]
        }
      ]
    }
  ]
}